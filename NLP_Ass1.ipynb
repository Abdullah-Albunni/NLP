{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Import library"
      ],
      "metadata": {
        "id": "tQPsCqZwj4wc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "import nltk\n",
        "import warnings\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OBg7cxECkBVv",
        "outputId": "15e8a375-da6d-4049-cae5-10b91a54b55e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocesing Data"
      ],
      "metadata": {
        "id": "KIfZLugBkGmR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "R31dLt-Wk54Z"
      },
      "outputs": [],
      "source": [
        "html = requests.get(url='https://en.wikipedia.org/wiki/Main_Page').text\n",
        "soup = BeautifulSoup(html, features=\"html.parser\")\n",
        "\n",
        "# Extract text from HTML\n",
        "text = soup.get_text()\n",
        "\n",
        "# Remove HTML tags\n",
        "text = re.sub(r'<[^>]*>', '', text)\n",
        "\n",
        "# Cleaning the text\n",
        "text = re.sub(r\"[^a-zA-Z\\s]\", \"\", text)\n",
        "\n",
        "# Lower case\n",
        "text = text.lower()\n",
        "\n",
        "# Splitting the text\n",
        "text = text.split()\n",
        "\n",
        "# Stemming\n",
        "stemmer = PorterStemmer()\n",
        "text = [stemmer.stem(word) for word in text]\n",
        "\n",
        "# Removing stop words\n",
        "stop_words = set(stopwords.words('english'))\n",
        "text = [word for word in text if word not in stop_words]\n",
        "\n",
        "# Remove duplicates and single letters\n",
        "text = [word for word in text if len(word) > 1]\n",
        "\n",
        "# Remove duplicates again\n",
        "text = list(set(text))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Unique words"
      ],
      "metadata": {
        "id": "4ywfbYAZkU2C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(text)\n",
        "print(len(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qTDNc6shkUWk",
        "outputId": "f04eeb09-cb74-482a-8071-1b4250e9d950"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['shape', 'news', 'sourc', 'encyclopedia', 'care', 'kingdom', 'michael', 'nba', 'catal', 'etina', 'mass', 'printexport', 'player', 'adult', 'legisl', 'time', 'found', 'deutsch', 'pageget', 'mozart', 'befor', 'cartoon', 'establish', 'welcom', 'raisbeck', 'upon', 'encycloped', 'bishop', 'march', 'forum', 'inc', 'inde', 'simpl', 'wiktionarydictionari', 'page', 'pictur', 'specialis', 'sent', 'cell', 'frere', 'statist', 'portray', 'hub', 'elect', 'linear', 'hivassoci', 'carolsfeld', 'first', 'slovenina', 'safavid', 'grey', 'broader', 'develop', 'brolyleg', 'oliv', 'sea', 'wikispeciesdirectori', 'myanmar', 'front', 'written', 'ramda', 'trial', 'nynorsk', 'retriev', 'focu', 'contribut', 'foundationmediawikimetawikiwikimedia', 'war', 'incorpor', 'shorten', 'juri', 'penrith', 'articleabout', 'charact', 'review', 'aground', 'rang', 'bodi', 'knowledg', 'pdfprintabl', 'commonswikimedia', 'technic', 'view', 'civil', 'norwich', 'bosanski', 'kill', 'sigeberht', 'fruit', 'boyi', 'term', 'wikinewsfreecont', 'svenska', 'ukrain', 'ask', 'practition', 'steve', 'democrat', 'patient', 'adud', 'utc', 'portalrec', 'mainstream', 'church', 'sourceview', 'translat', 'bokmlnorsk', 'felixstow', 'nonprofit', 'volunt', 'magyar', 'haitian', 'outreachmultilingu', 'fiction', 'wikiversityfre', 'hererel', 'code', 'qr', 'east', 'seed', 'elsewher', 'gulf', 'von', 'portug', 'mcqueen', 'stripe', 'colour', 'languag', 'music', 'wolf', 'limit', 'search', 'central', 'pump', 'abbey', 'inner', 'ron', 'indigen', 'harrison', 'covert', 'month', 'fouryear', 'either', 'europ', 'reconquista', 'industri', 'neurocognit', 'canterburi', 'dunwich', 'scotland', 'pagesperman', 'action', 'wikidatafre', 'contract', 'uniqu', 'media', 'suomisvenskatrket', 'shoot', 'frankish', 'hendrotomo', 'kelsey', 'travel', 'urldownload', 'control', 'print', 'softwar', 'hi', 'london', 'psycholog', 'alexand', 'collar', 'contact', 'introduc', 'nationalist', 'trademark', 'argosi', 'push', 'rest', 'melayu', 'outer', 'ill', 'cooki', 'pagetalk', 'suomi', 'franai', 'file', 'persian', 'mediawikiwiki', 'hrvatski', 'link', 'new', 'putin', 'tensi', 'speci', 'faz', 'may', 'metallicbrittl', 'eesti', 'grant', 'diomay', 'saint', 'account', 'lauritano', 'list', 'announc', 'collect', 'fay', 'vladimir', 'largest', 'crocu', 'sukadji', 'email', 'ozbekcha', 'linkpag', 'licens', 'instrument', 'name', 'foundat', 'estrildid', 'basic', 'snap', 'spread', 'brow', 'commun', 'ta', 'last', 'near', 'diseas', 'physicianassist', 'onli', 'question', 'invas', 'francia', 'portal', 'disord', 'way', 'hall', 'download', 'krasnogorsk', 'explos', 'wing', 'edit', 'italiano', 'refer', 'indonesia', 'guid', 'approv', 'ship', 'frysk', 'angelo', 'histori', 'research', 'fall', 'tablet', 'onto', 'topic', 'contributionstalk', 'seek', 'liter', 'gerri', 'creat', 'billboard', 'san', 'russian', 'kurd', 'spanish', 'die', 'ran', 'bnlmg', 'mark', 'manual', 'jump', 'statu', 'laufey', 'ramsey', 'accord', 'text', 'refug', 'south', 'wikipedia', 'american', 'honoriu', 'codewikidata', 'villag', 'secur', 'seneg', 'wikibooksfre', 'informationcit', 'srpskisrpskohrvatski', 'jo', 'inch', 'archiv', 'english', 'genr', 'agre', 'latvieu', 'game', 'coordin', 'euskara', 'helplearn', 'issu', 'avail', 'photograph', 'galego', 'version', 'sidebar', 'blueprint', 'john', 'juvenil', 'onc', 'kenneth', 'bosanskicataletinadanskdeutscheestiespaolesperantoeuskarafranaisgalegohrvatskibahasa', 'basra', 'nederland', 'forc', 'allianc', 'suffolk', 'addit', 'tradit', 'attributionsharealik', 'priest', 'death', 'billi', 'dedic', 'melayunederlandsnorsk', 'librari', 'year', 'entir', 'rebellion', 'elbridg', 'wikipediacontact', 'laxminarayan', 'israelhama', 'disclaim', 'soham', 'full', 'oddli', 'space', 'toggl', 'allenbya', 'project', 'baynham', 'vit', 'srpskohrvatski', 'mobil', 'regist', 'modern', 'prove', 'ting', 'neochmia', 'sickl', 'julievictoir', 'boston', 'polici', 'timelin', 'match', 'eye', 'russia', 'thesauru', 'crisi', 'approach', 'bede', 'temporali', 'thi', 'began', 'hide', 'common', 'know', 'shqip', 'learn', 'dansk', 'subsequ', 'man', 'angl', 'move', 'back', 'muslim', 'content', 'person', 'relic', 'collinsona', 'seat', 'governor', 'area', 'mancroft', 'novelist', 'columbanusfelix', 'peopl', 'monasteri', 'organ', 'site', 'red', 'daubi', 'help', 'redbrow', 'elector', 'see', 'englishsloveninaslovenina', 'occup', 'statement', 'indonesiaitalianolatvieulietuvimagyarbahasa', 'citi', 'presidenti', 'least', 'scienc', 'irish', 'anglia', 'gerrymand', 'sever', 'footbal', 'cunco', 'nynorskpolskiportugusromnsimpl', 'schnorr', 'filespeci', 'tool', 'ventri', 'thoma', 'burgundi', 'anyon', 'recent', 'st', 'aldawla', 'river', 'conduct', 'ottoman', 'archbishop', 'item', 'menu', 'end', 'also', 'eventsrandom', 'credit', 'cola', 'resourc', 'androgyn', 'possibl', 'ulyss', 'coast', 'magazin', 'countri', 'day', 'deceas', 'termin', 'district', 'win', 'discuss', 'jr', 'bahasa', 'base', 'note', 'portugu', 'mildmay', 'wikisourcefreecont', 'solemn', 'despit', 'creativ', 'editor', 'peter', 'teahous', 'empir', 'murder', 'walton', 'log', 'one', 'pageo', 'featur', 'school', 'jack', 'main', 'host', 'width', 'anniversari', 'deciph', 'textbook', 'bright', 'garrett', 'winner', 'polski', 'movement', 'appli', 'editcommun', 'fifth', 'came', 'christian', 'castil', 'infatu', 'almost', 'australia', 'algecira', 'suicid', 'articl', 'bassir', 'wikivoyagefre', 'nearli', 'lack', 'srpski', 'wa', 'ongo', 'pagecontentscurr', 'flight', 'known', 'readview', 'asturianu', 'rump', 'wikiquotecollect', 'espaol', 'inhabit', 'crew', 'final', 'gener', 'deliber', 'wikimedia', 'privaci', 'cherubino', 'sieg', 'desk', 'offens', 'daughter', 'wikisourcewikispecieswikibookswikidatawikifunctionswikimaniawikinewswikiquotewikisourcewikiversitywikivoyagewiktionari', 'jazz', 'changesupload', 'abov', 'metawikiwikimedia', 'gazett', 'distinguish', 'presid', 'py', 'gaeilg', 'httpsenwikipediaorgwindexphptitlemainpageoldid', 'finch', 'trke', 'start', 'navig', 'juliu', 'sister', 'mani', 'marriag', 'nomin', 'felix', 'rehabilit', 'long', 'free', 'norsk', 'bokml', 'romn', 'includ', 'arriv', 'lietuvi', 'gave', 'use', 'charg', 'repositori', 'mission', 'quotat', 'dommoc', 'surrend', 'kevorkian', 'thousand', 'hospit', 'centimetr', 'esperanto', 'wale', 'chlon', 'today', 'missionari', 'wide', 'basi', 'coin', 'task', 'commonsfre', 'usdon']\n",
            "571\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in text:\n",
        "  if len(i) < 3:\n",
        "    print(i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bd_zrwuclHGu",
        "outputId": "d7e1c5e0-c164-4bf5-c66a-da382d82238b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "qr\n",
            "hi\n",
            "ta\n",
            "jo\n",
            "st\n",
            "jr\n",
            "wa\n",
            "py\n"
          ]
        }
      ]
    }
  ]
}